{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88tCXKMAp2FX"
   },
   "source": [
    "#  Barclays x GA: Python Day 3 - Pandas and EDA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NyAoZKZp2FZ"
   },
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "## Learning Objectives\n",
    "*After completing this notebook, you will be able to:*\n",
    "\n",
    "- Define what Pandas is and how it relates to data science.\n",
    "- Manipulate Pandas `DataFrames` and `Series`.\n",
    "- Filter and sort data using Pandas.\n",
    "- Manipulate `DataFrame` columns.\n",
    "- Understand the different kinds of missing data, and know how to handle null and missing values.\n",
    "- Visualise data with a range of different charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzq3TuChp2Fa"
   },
   "source": [
    "## Contents:\n",
    "* [Introduction to Pandas](#pandas-intro)\n",
    "* [DataFrame methods and attributes](#dataframe-methods)\n",
    "* [Setting values](#setting-values)\n",
    "* [Selecting columns](#selecting-cols)\n",
    "* [Transforming columns](#transforming-cols)\n",
    "* [Selecting rows](#selecting-rows)\n",
    "* [Sorting data](#sorting-data)\n",
    "* [Missing data](#missing-data)\n",
    "* [Value counts](#value-counts)\n",
    "* [Grouping](#groupby)\n",
    "* [Visualisations](#visualisations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pandas-intro\"></a>\n",
    "\n",
    "# <font color='blue'> Introduction to Pandas\n",
    "\n",
    "Pandas is a Python library that primarily adds two new datatypes to Python: `DataFrame` and `Series`.\n",
    "\n",
    "- A `Series` is a sequence of items, where each item has a unique label (called an `index`).\n",
    "- A `DataFrame` is a table of data. Each row has a unique label (the `row index`), and each column has a unique label (the `column index`).\n",
    "- Note that each column in a `DataFrame` can be considered a `Series` (`Series` index).\n",
    "\n",
    "Behind the scenes, these datatypes use the `numpy` (numerical Python) library. NumPy primarily adds the `ndarray` (n-dimensional array) datatype to Pandas. An `ndarray` is similar to a Python list, in that it stores ordered data. However, it differs in three respects:\n",
    "\n",
    "* Each element has the same datatype (typically fixed-size, e.g., a 32-bit integer).\n",
    "* Elements are stored contiguously (immediately after each other) in memory for fast retrieval.\n",
    "* The total size of an `ndarray` is fixed.\n",
    "\n",
    "Storing `Series` and `DataFrame` data in `ndarray`s makes Pandas faster and uses less memory than standard Python datatypes. Many libraries (such as scikit-learn) accept `ndarray`s as input rather than Pandas datatypes, so we will frequently convert between them.\n",
    "\n",
    "\n",
    "## Using Pandas\n",
    "\n",
    "Pandas is frequently used in data science because it offers a large set of commonly used functions, is relatively fast, and has a large community. Because many data science libraries also use NumPy to manipulate data, you can easily transfer data between libraries (as we will often do in this class!).\n",
    "\n",
    "Pandas is a large library that typically takes a lot of practice to learn. \n",
    "\n",
    "It heavily overrides Python operators, resulting in odd-looking syntax. For example, given a `DataFrame` called `cars` which contains a column `mpg`, we might want to view all cars with mpg over 35. To do this, we might write: `cars[cars['mpg'] > 35]`. \n",
    "\n",
    "In standard Python, this would most likely give a syntax error.  \n",
    "\n",
    "Pandas also highly favors certain patterns of use. \n",
    "\n",
    "For example, looping through a `DataFrame` row by row is highly discouraged. \n",
    "\n",
    "Instead, Pandas favors using **vectorized functions** that operate column by column. (This is because each column is stored separately as an `ndarray`, and NumPy is optimized for operating on `ndarray`s.)\n",
    "\n",
    "Do not be discouraged if Pandas feels overwhelming. Gradually, as you use it, you will become familiar with which methods to use and the \"Pandas way\" of thinking about and manipulating data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='red'> Exercise: Reading in pay gap data\n",
    "    \n",
    "Today we'll be working with a dataset on the gender pay gap across companies in the UK. \n",
    "\n",
    "Let's start by reading in a CSV as a Pandas `DataFrame`.\n",
    "\n",
    "1. Use the `read_csv()` Pandas function to read in a file from the `Data` directory (which is inside the directory this notebook is in). \n",
    "\n",
    "The file has been downloaded from https://gender-pay-gap.service.gov.uk/viewing/download. It's called `UK Gender Pay Gap Data - 2019 to 2020.csv`; read this in as a DataFrame called `pay_gap_2019_20`\n",
    "    \n",
    "\n",
    "2. Use the `head` command on `pay_gap_2019_20` to visually inspect the data. What's strange about it? Use `read_csv()` again but try playing around with the `header` parameter (e.g. `read_csv(header=5)`) until the final DataFrame looks right. What does the `header` parameter do?\n",
    "\n",
    "\n",
    "3. Continue to inspect `pay_gap_2019_20` visually and figure out:\n",
    "\n",
    "    \n",
    "* What the data contains\n",
    " \n",
    "* What each column corresponds to\n",
    "    \n",
    "* What each row corresponds to\n",
    "    \n",
    "\n",
    "3. Use `shape` to figure out how many rows are in `pay_gap_2019_20`. \n",
    "\n",
    "4. List as many potential data quality issues as you can in `pay_gap_2019_20`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dataframe-methods\"></a>\n",
    "\n",
    "# <font color='blue'> DataFrame Methods and Attributes\n",
    "\n",
    "We've seen that Pandas `DataFrame` is perhaps the most important class of object in Pandas, and comes with a set of attributes (or properties) and methods that can be applied specifically to Pandas ``DataFrames``. \n",
    "\n",
    "We start by importing ``pandas`` and reading in a CSV file using the ``read_csv`` function. The ``header=2`` parameter specifies that the column names are in row ``2`` of the underlying CSV file.\n",
    "\n",
    "We preview the first five rows of the ``DataFrame`` using the ``head`` method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20 = pd.read_csv('./data/UK Gender Pay Gap Data - 2019 to 2020.csv',header=2)\n",
    "pay_gap_2019_20.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the index, which is a numbering system that labels each row with a unique number according to its position in the DataFrame (like indexing in a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly access the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``shape`` attribute is a good way of figuring out how big our dataset is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that our ``DataFrame`` is the correct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pay_gap_2019_20)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Checking data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the types of data in individual columns. **But first, we need to deliberately engineer a problem with our data by running the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20 = pay_gap_2019_20.astype({'DiffMedianHourlyPercent': 'str',\n",
    "                                         'DiffMeanBonusPercent': 'str',\n",
    "                                         'DiffMeanHourlyPercent':'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the types using `dtypes()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the columns in our dataset are ``float64``, i.e. floating point or **decimal** numbers.\n",
    "\n",
    "But we can also see that the `DiffMeanHourlyPercent`, `DiffMedianHourlyPercent` and `DiffMeanBonusPercent` columns are **not** a numeric type. If a column in a DataFrame contains a mix of types, Pandas labels its type as `object`.\n",
    "\n",
    "Since we want Pandas to treat these columns as numeric columns, we need to convert it using the `to_numeric` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['DiffMeanHourlyPercent'] = pd.to_numeric(pay_gap_2019_20['DiffMeanHourlyPercent'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we run `dtypes` again, we can see the `DiffMeanHourlyPercent` column has a numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That leaves the `DiffMedianHourlyPercent` and `DiffMeanBonusPercent` columns to convert. Instead of running `to_numeric()` two more times, it's more efficient to convert multiple columns to different types using the `astype` method.\n",
    "\n",
    "**Note that the information we give Pandas about which columns to convert, and which types to convert them to, is formatted as a dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20 = pay_gap_2019_20.astype({'DiffMedianHourlyPercent': 'float64',\n",
    "                                         'DiffMeanBonusPercent': 'float64'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `dtypes` a final time, we see that all the columns in our DataFrame are of the correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setting-values\"></a>\n",
    "\n",
    "# <font color='blue'> Setting values in a DataFrame\n",
    "\n",
    "To change the value of a single element in a DataFrame, we use the `at` method.\n",
    "\n",
    "We pass it the position of the element we want to set the value of, in the format `[index,column_name]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.at[0,'Address'] = 'test value 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"selecting-cols\"></a>\n",
    "\n",
    "# <font color='blue'> Selecting columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames have structural similarities with Python-style lists and dictionaries. We can select, or extract, columns from a `DataFrame` using column names.\n",
    "\n",
    "\n",
    "\n",
    "In the example below, we select a column of data using the name of the column in a similar manner to how we select a dictionary value with the dictionary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay_gap_2019_20['EmployerName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a Pandas **series**. We can think of this as being the Pandas equivalent of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pay_gap_2019_20['EmployerName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a single column using this syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay_gap_2019_20[['EmployerName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pay_gap_2019_20[['EmployerName']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select multiple columns using this syntax too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20[['EmployerName','Address']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neater way of doing it could be using this syntax, which does exactly the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_select = ['EmployerName','Address']  \n",
    "\n",
    "pay_gap_2019_20[columns_to_select]            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"transforming-cols\"></a>\n",
    "\n",
    "# <font color='blue'> Transforming columns\n",
    "    \n",
    "Once we've selected columns, we can perform transformations on them (e.g converting an entire column to lowercase) or calculations with them (e.g. adding two columns together to create a new column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing column names\n",
    "\n",
    "There are a few different ways to change column names. \n",
    "\n",
    "### Renaming individual columns\n",
    "\n",
    "Individual column names can be changed like this. We could add as many columns as we wanted to the dictionary below, in the format `{'old_column_name':'new_column_name'}`\n",
    "\n",
    "`rename` is by default **not** an **in place** method, i.e. it doesn't change the underlying DataFrame. In order to make methods **in place** we need to add an extra input to the `rename` method; `inplace=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.rename(columns={'Address':'EmployerAddress'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the column has been renamed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to rename **all** the columns in a DataFrame using the syntax\n",
    "\n",
    "``DataFrame.columns = [full list of new column names]``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new columns\n",
    "\n",
    "We can create new columns by performing calculations on existing columns. Let's say we want to create a new column that gives the Difference in Mean Hourly Pay as a proportion rather than a percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['DiffMeanHourlyPercent']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['DiffMeanHourlyProportion'] = pay_gap_2019_20['DiffMeanHourlyPercent']/100\n",
    "pay_gap_2019_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns\n",
    "\n",
    "We can use the `drop` method to do this. Once again, unless we specify that the method is `inplace` the underlying DataFrame won't be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.drop(columns=['DateSubmitted','DueDate'],inplace=True)\n",
    "pay_gap_2019_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions to columns\n",
    "\n",
    "Sometimes we'll want to perform a calculation or operation on each row of a DataFrame column. There are a few different ways to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorised functions\n",
    "\n",
    "In Pandas it's discouraged to loop through all the rows in a DataFrame, applying a function or operation to each row. \n",
    "\n",
    "Vectorised functions, which quickly apply a function to an entire column without having to explicitly write a loop, are much faster and more efficient. \n",
    "\n",
    "Here are some examples.\n",
    "\n",
    "We can convert columns to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['EmployerName'] = pay_gap_2019_20['EmployerName'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace strings. This can be used to remove strings, too by replacing them with a blank space or `''`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['EmployerName'] = pay_gap_2019_20['EmployerName'].str.replace('limited','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform calculations with entire columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['DiffMedianHourlyPercent']*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='red'> Exercise: Column calculations\n",
    "    \n",
    "1. Figure out how to use the `mean()` `DataFrame` method to work out the mean value of the \n",
    "`DiffMeanHourlyPercent` column.\n",
    "\n",
    "\n",
    "2. Drop the `FemaleTopQuartile` column from the `DataFrame`.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"selecting-rows\"></a>\n",
    "\n",
    "# <font color='blue'> Selecting rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting rows by index\n",
    "\n",
    "We can use the `loc` command to pick out a specific row of a DataFrame.\n",
    "\n",
    "We use the syntax `loc[a,b]` where `a` is the index of the row we want to access, and `b` is the name of the column. \n",
    "\n",
    "As with lists, `:` means 'give me everything' so in this example below, we're accessing the **first** row of data and **all** the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.loc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a **range** of rows we want to extract. This gives us rows **0** to **2** **inclusive of row 5** and all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.loc[0:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify rows and single columns, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.loc[0:2,'EmployerName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the rows we want plus the list of columns we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.loc[0:2,['EmployerName','EmployerAddress']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, the rows we want and the **range** of columns we want (notice the `:` operator again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.loc[0:2,'EmployerName':'SicCodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting rows using logical tests\n",
    "\n",
    "Often we won't know the exact index of the row we're looking for. \n",
    "\n",
    "Maybe we want to find all the rows where the `DiffMedianHourlyPercent` is greater than 10%.\n",
    "\n",
    "We start by writing a **filter** or a logical test that will be `True` for the rows we're interested in. \n",
    "\n",
    "We're interested in the `DiffMedianHourlyPercent` column so our filter looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_filter = pay_gap_2019_20['DiffMedianHourlyPercent']>10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we inspect this filter, we can see it's a long list of `True` and `False` values; the value of the filter is `True` for rows that pass the logical test and `False` for rows that don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we **apply** our filter to our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20[pay_gap_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write and apply our filter in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pay_gap_2019_20[pay_gap_2019_20['DiffMedianHourlyPercent']>10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to combine logical tests using `and` and `or` operators. For example, to find all rows where `DiffMedianHourlyPercent` is greater than 10% **and** `DiffMeanHourlyPercent` is greater than 10%, we can write:\n",
    "\n",
    "**Note that the `and` operator here is written as `&`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_filter_2 = (pay_gap_2019_20['DiffMedianHourlyPercent']>10) & (pay_gap_2019_20['DiffMeanHourlyPercent']>10)\n",
    "\n",
    "pay_gap_2019_20[pay_gap_filter_2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to find all rows where `DiffMedianHourlyPercent` is greater than 10% **or** `DiffMeanHourlyPercent` is greater than 10%, we can write:\n",
    "\n",
    "**Note that the `or` operator here is written as `|`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_filter_3 = (pay_gap_2019_20['DiffMedianHourlyPercent']>10) | (pay_gap_2019_20['DiffMeanHourlyPercent']>10)\n",
    "\n",
    "new_df = pay_gap_2019_20[pay_gap_filter_3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the ``str.contains()`` method to find all rows that contain a particular string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['EmployerName'].str.lower().str.contains('school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_filter_4 = pay_gap_2019_20['EmployerName'].str.lower().str.contains('school')\n",
    "\n",
    "pay_gap_2019_20[pay_gap_filter_4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='red'> Exercise: Filtering rows and columns\n",
    "    \n",
    "    \n",
    "1. Select companies where the median hourly pay gap is in favour of women, i.e. where `DiffMedianHourlyPercent` is **negative**\n",
    "\n",
    "\n",
    "2. Select companies that have 'college' in the name\n",
    "\n",
    "\n",
    "3. Select companies that have a mean hourly pay gap greater than 10%, i.e. where `DiffMeanHourlyPercent` is greater than 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sorting-data\"></a>\n",
    "\n",
    "# <font color='blue'> Sorting data\n",
    "    \n",
    "It's easy to sort data in ascending/descending order according to a particular column. We do this using the `sort_values` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay_gap_2019_20.sort_values(by='DiffMedianHourlyPercent',ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='red'> Exercise: Sorting data\n",
    "    \n",
    "1. Which company has the lowest median hourly pay gap?\n",
    "\n",
    "\n",
    "2. Which companies have the top 5 highest mean hourly pay gap?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-data\"></a>\n",
    "# <font color='blue'> Handling missing values\n",
    "    \n",
    "Sometimes, values will be missing from the source data or as a byproduct of manipulations. It is very important to detect missing data. Missing data can:\n",
    "\n",
    "- Make the entire row ineligible to be training data for a model.\n",
    "- Hint at data-collection errors.\n",
    "- Indicate improper conversion or manipulation.\n",
    "- Actually not be missing â€” it sometimes means \"zero,\" \"false,\" \"not applicable,\" or \"entered an empty string.\"\n",
    "\n",
    "In Pandas, a \"null\" value is either `None` or `np.NaN` (Not a Number). \n",
    "\n",
    "Many fixed-size numeric datatypes (such as integers) do not have a way of representing `np.NaN`. So, numeric columns will be promoted to floating-point datatypes that do support it.\n",
    "\n",
    "Let's check our gender pay gap dataset for missing values.\n",
    "\n",
    "We can do this using the `isnull()` method and summing up the values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to drop rows containing ``NaN`` values, or fill in ``NaN`` values with a string, float or other element of our choice. \n",
    "\n",
    "Be careful when doing either of these things; you could end up unintentionally removing rows, or filling in values that don't make sense or aren't accurate.\n",
    "\n",
    "In this case, it would be important to clarify whether a ``NaN`` value in a particular column means the amount is zero, or whether it means the amount is unknown.\n",
    "\n",
    "We can **fill in** NaN values with a value of our choice using `fillna()`. For example, it makes sense to fill in `CompanyLinkToGPGInfo` with a string like 'no URL provided'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['CompanyLinkToGPGInfo'].fillna('No URL',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that this column no longer has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to **drop** rows where there is no company number provided, since this means we won't be able to look up the company on Companies House."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.dropna(subset=['CompanyNumber'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can now see that there are no missing values in the `CompanyNumber` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay_gap_2019_20.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary-stats\"></a>\n",
    "\n",
    "# <font color='blue'> Summary statistics\n",
    "\n",
    "Pandas has a bunch of built-in methods to quickly summarize your data and provide you with a quick general understanding. \n",
    "\n",
    "The ``describe`` method gives summary statistics for the numeric columns in the data.\n",
    "\n",
    "Let's start by reading in our pay gap data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to get summary statistics for all columns, including non-numeric ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to compute statistics like the median for individual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['DiffMeanHourlyPercent'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='red'> Exercise: Descriptive statistics\n",
    "    \n",
    "Interpret the results above to answer the following questions:\n",
    "\n",
    "* What's the mean % difference in hourly pay between men and women, across all companies?\n",
    "* What's the median % difference in hourly pay between men and women, across all companies?\n",
    "\n",
    "\n",
    "Use your knowledge of `isna()` to figure out:\n",
    "\n",
    "* How many companies haven't provided a website address?\n",
    "* How many companies don't give their employees bonuses? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"value-counts\"></a>\n",
    "# <font color='blue'> Getting value counts\n",
    "\n",
    "Sometimes we might want to see the breakdown of different values in a column. This is easy with the `value_counts` function.\n",
    "\n",
    "In our gender dataset, let's check the breakdown of company sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20[['EmployerSize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20['EmployerSize'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay_gap_2019_20['EmployerSize'].value_counts('normalize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='red'> Exercise: Value counts\n",
    "    \n",
    "Interpret the results above to answer the following questions:\n",
    "\n",
    "* What's the mean % difference in hourly pay between men and women, across all companies?\n",
    "* What's the median % difference in hourly pay between men and women, across all companies?\n",
    "\n",
    "\n",
    "Use your knowledge of `isna()` to figure out:\n",
    "\n",
    "* How many companies haven't provided a website address?\n",
    "* How many companies don't give their employees bonuses? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"groupby\"></a>\n",
    "# <font color='blue'> Grouping data\n",
    "\n",
    "Sometimes we might want a more detailed breakdown using more than one column. \n",
    "\n",
    "Let's look at the mean pay gap across all companies, grouped by company size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_gap_2019_20.groupby('EmployerSize')['DiffMeanHourlyPercent'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, is there a relationship between a company sizes and pay gaps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualisations\"></a>\n",
    "\n",
    "# <font color='blue'> Visualisations\n",
    "\n",
    "In this section, we'll learn about how plotting works in Pandas and Matplotlib. \n",
    "\n",
    "It'a important to know that Pandas uses Matplotlib behind the scenes to make plots. \n",
    "\n",
    "So, you will notice that Pandas plotting methods often use similar parameter names as Matplotlib methods. You can also use Matplotlib functions in combination with Pandas methods to alter the plots after drawing them. \n",
    "\n",
    "For example, you can use Matplotlib's `xlabel` and `title` functions to label the plot's x-axis and title, respectively, after it is drawn.\n",
    "\n",
    "As we explore different types of plots, notice:\n",
    "\n",
    "1. Different types of plots are drawn very similarly; they even tend to share parameter names.\n",
    "\n",
    "2. In Pandas, calling `plot()` on a `DataFrame` is different to calling it on a `Series`. Although the methods are both named `plot`, they may take different parameters.\n",
    "\n",
    "Toward the end of the lab, we will show some motivational plots using Seaborn, a popular statistics plotting library, as well as go more in-depth about how Matplotlib works.\n",
    "\n",
    "Pandas documentation is a good, comprehensive source of information on different plotting functions and parameters.\n",
    "\n",
    "[Link to Documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html)\n",
    "\n",
    "Let's start by importing the libraries we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and Pandas for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import the two data visualisation libraries we'll be using\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set some formatting parameters for this notebook\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Increase default figure and font sizes for easier viewing.\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color='red'> Code-along: Reading in credit risk data\n",
    "    \n",
    "Today we'll be working with a dataset from Kaggle, which gives information about people applying for loans. \n",
    "\n",
    "Take a few minutes to read more about the dataset here: https://www.kaggle.com/c/home-credit-default-risk/overview\n",
    "\n",
    "Then, read in the file `credit_risk.csv` from the `data` directory in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = pd.read_csv('./data/credit_risk.csv')\n",
    "credit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows and columns are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `head` to preview the first few rows of the dataset, and look at the column names. Here's an explanation of what each column means:\n",
    "\n",
    "* SK_ID_CURR: Client ID\n",
    "* TARGET: This is 1 if the client has made at least one late loan payment, 0 if not\n",
    "* CODE_GENDER: Gender of the client\n",
    "* FLAG_OWN_CAR:\tThis is 1 if the client owns a car, 0 if not\n",
    "* FLAG_OWN_REALTY: This is 1 if client owns a house or flat, 0 if not\n",
    "* CNT_CHILDREN:\tNumber of children the client has\n",
    "* AMT_INCOME_TOTAL:\tIncome of the client\n",
    "* AMT_GOODS_PRICE: For consumer loans it is the price of the goods for which the loan is given\n",
    "* AMT_CREDIT: Amount of the loan\n",
    "* NAME_INCOME_TYPE:\tClient's income type (businessman, working, maternity leave)\n",
    "* NAME_EDUCATION_TYPE: Level of highest education the client achieved\n",
    "* NAME_FAMILY_STATUS: Family status of the client\n",
    "* REGION_POPULATION_RELATIVE: Normalized population of region where client lives (higher number means the client lives in more populated region)\n",
    "* NAME_HOUSING_TYPE: What is the housing situation of the client (renting, living with parents, ...)\n",
    "* DAYS_BIRTH: Client's age in days at the time of application\n",
    "* DAYS_EMPLOYED: How many days before the application the person started current employment\n",
    "* OCCUPATION_TYPE: What kind of occupation does the client have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"histograms\"></a>\n",
    "\n",
    "# <font color='blue'> Histograms\n",
    "\n",
    "Histograms show the spread of values within a single variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a histogram to show the spread of the number of children people have.\n",
    "\n",
    "We set the number of buckets, or bars, to 20 and specify the limits of the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df['CNT_CHILDREN'].hist(bins=5,range=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this histogram tell us?\n",
    "\n",
    "* Most people applying for a loan have 0 children\n",
    "* This histogram doesn't follow a 'bell curve' shape so we can say this variable isn't **normally distributed**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise: Histograms\n",
    "    \n",
    "Make histograms to show the spread of each of these variables:\n",
    "* Client income: Set the number of bins to 10, and the x-axis range from 0 to 600,000\n",
    "* Loan amount: Set the number of bins to 20, and the x-axis range from 0 to 2,500,000\n",
    "\n",
    "Interpret these histograms, including:\n",
    "* Are the variables **normally distributed**?\n",
    "* Roughly what's the most commonly requested loan amount?\n",
    "* What's the most common earnings bracket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bar-charts\"></a>\n",
    "\n",
    "# <font color='blue'> Bar charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple bar charts\n",
    "\n",
    "Now we want to make a visualisation to show how many loans were granted to people with different levels of education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df['NAME_EDUCATION_TYPE'].value_counts().plot(kind='bar',title='Loan applications by education level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise: Bar charts\n",
    "    \n",
    "Make bar charts showing:\n",
    "\n",
    "* The different marital statuses of clients\n",
    "* The housing situations of clients\n",
    "\n",
    "Interpret each bar chart to figure out:\n",
    "\n",
    "* What the most common marital status is for loan applicants\n",
    "* What the most and least common housing situation is for loan applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"box-plots\"></a>\n",
    "# <font color='blue'> Box plots\n",
    "\n",
    "We can use boxplots to quickly summarize distributions and get a **five-number summary** of a dataset:\n",
    "\n",
    "- min = minimum value\n",
    "- 25% = first quartile (Q1) = median of the lower half of the data\n",
    "- 50% = second quartile (Q2) = median of the data\n",
    "- 75% = third quartile (Q3) = median of the upper half of the data\n",
    "- max = maximum value\n",
    "\n",
    "**Interquartile Range (IQR)** = Q3 - Q1\n",
    "\n",
    "**Outliers:**\n",
    "\n",
    "- below Q1 - 1.5 * IQR\n",
    "- above Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df['AMT_INCOME_TOTAL'].plot(kind='box');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the boxplots of income broken down by gender. This plot tells us:\n",
    "\n",
    "* On average, male customers tend to earn more than women\n",
    "* The **range** of women's salaries is smaller than men's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.boxplot(column='AMT_INCOME_TOTAL', by='CODE_GENDER',figsize=(10,8));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise: Box plots\n",
    "    \n",
    "Make box plots to answer the following questions.\n",
    "\n",
    "* Do men tend to apply for larger loans than women?\n",
    "* Do people with higher levels of education have higher salaries on average?\n",
    "* Do people with higher levels of education have more debt?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scatter-plots\"></a>\n",
    "\n",
    "# <font color='blue'> Scatter plots\n",
    "    \n",
    "Scatter plots can be used to show the relationship between two variables. \n",
    "\n",
    "Let's do this using the credit dataset, to show the relationship between income and loan amount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.plot(kind='scatter',x='AMT_INCOME_TOTAL',y='AMT_CREDIT',xlim=(0,1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this scatter plot tell us? \n",
    "* It looks like there's a positive correlation between a person's income and the size of the loan they're applying for\n",
    "\n",
    "We can change the transparency of the dots to 0.3 using the `alpha` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.plot(kind='scatter',x='AMT_INCOME_TOTAL',y='AMT_CREDIT',xlim=(0,1000000),alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's the colour of each point according to the value of the `TARGET` column, so each point is coloured according to whether a client has made a late payment or not. We do this using the `c` argument and the `colormap` option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.plot(kind='scatter',x='AMT_INCOME_TOTAL',y='AMT_CREDIT',\n",
    "                          c='TARGET',xlim=(0,1000000),colormap='bwr',alpha=0.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise: Scatter plots\n",
    "    \n",
    "Make scatter plots to answer the following questions.\n",
    "\n",
    "* Is there a correlation between a person's age **in years** and the size of the loan they're applying for? You'll need to create a new column in the DataFrame, containing the client's age in years.\n",
    "\n",
    "* Is there a correlation between how many **years** a person has been employed for, and the size of the loan they're applying for? Again, you'll need to create a new column in the DataFrame containing the length of the client's employment in years.\n",
    "\n",
    "You might need to use the following options to format your scatter plots:\n",
    "* `xlim` and `ylim` to set the axis limits\n",
    "* `alpha` to set the transparency of the points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pair-plots\"></a>\n",
    "\n",
    "# <font color='blue'> Pair plots\n",
    "    \n",
    "Often when we're exploring a large dataset, we'll want to answer questions like:\n",
    "* What's the best subset of features to use in my model?\n",
    "* Which of my features have the strongest relationship with my dependent variable?\n",
    "* Which features have no correlation with my dependent variable so I can ditch them?\n",
    "* What kind of relationship exists between a pair of variables? Is it linear, or something else?\n",
    "\n",
    "Pair plots are a quick way of seeing the relationships between all the variables in our dataset in one go, and saves the hassle of having to generate lots of scatter plots one by one.\n",
    "\n",
    "**Again, we're only plotting the first 1000 rows of the dataset; plotting the whole dataset might slow your computers down!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(credit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"correlation-matrix\"></a>\n",
    "\n",
    "# <font color='blue'> Correlation matrix\n",
    "    \n",
    "Correlation (or the correlation coefficient) tells us whether thereâ€™s an association between two variables. It can only take values from -1 to 1. \n",
    "\n",
    "A strongly positive correlation between two variables X and Y means:\n",
    "* When X is high, Y is high \n",
    "* When X is low, Y is low \n",
    "\n",
    "A strongly negative correlation between two variables X and Y means:\n",
    "* When X is high, Y is low \n",
    "* When X is low, Y is high \n",
    "\n",
    "A correlation close to zero between two variables X and Y means thereâ€™s no association between them, and both variables are just doing their own thing. \n",
    "\n",
    "A correlation matrix shows the correlation coefficient between every pair of variables in a dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(credit_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color='red'> Exercise: US election data \n",
    "    \n",
    "Use pandas to read in the file `us_presidential_votes.csv` from the `data` folder, as a DataFrame called `votes`. \n",
    "\n",
    "Visually inspect the `DataFrame`. What do you think it contains? What does each row correspond to, and what does each column represent? Use the information available at https://www.kaggle.com/joelwilson/2012-2016-presidential-elections to help you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `columns` method to get a list of all the columns in the dataset. You'll need to refer back to this list when answering the questions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `describe()` to find:\n",
    "\n",
    "* The mean population across all counties\n",
    "* The mean population density across all counties\n",
    "* The smallest vote share achieved by Trump in any county\n",
    "* The largest vote share achieved by Clinton in any county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a histogram showing the spread of values for Trump's vote share across all counties. Is this variable normally distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a scatter plot to show the relationship between the proportion of people with a batchelors degree in a county, and Trump's vote share in that county. How can we interpret this scatter plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a scatter plot to show the relationship between the proportion of over-65s in a county, and Trump's vote share in that county. How can we interpret this scatter plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to find out which demographic features in a county are most strongly correlated with a high vote share for Trump. Use a combination of correlation matrices and correlation heatmaps to decide on **one** variable that you think is the strongest predictor of Trump's vote share in a county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_to_python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
