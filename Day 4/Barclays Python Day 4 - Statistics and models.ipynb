{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88tCXKMAp2FX"
   },
   "source": [
    "#  Barclays x GA: Python Day 4 - Statistics and models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NyAoZKZp2FZ"
   },
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "## Learning Objectives\n",
    "*After completing this notebook, you will be able to:*\n",
    "\n",
    "- Code up a predictive model where the coefficients are already known\n",
    "- Run simple linear regression in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzq3TuChp2Fa"
   },
   "source": [
    "## Contents:\n",
    "* [Introduction to Linear regression](#regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleaning\"></a>\n",
    "\n",
    "# <font color='blue'> What is linear regression?\n",
    "\n",
    "\n",
    "Linear regression is a way of modelling some depdendent variable $y$ as a linear combination of one or more independent variables $x$.\n",
    "\n",
    "We are often taught the formula for a straight line is: $y = mx + b$.\n",
    "\n",
    "This can alternatively be written as: $$y = \\beta_{0} + \\beta_{1} x$$\n",
    "\n",
    "## What are the independent and dependent variables in this formula?\n",
    "\n",
    "In regression tasks, the **dependent** variable is continuous. In classification tasks, the **dependent** variable is categorical. \n",
    "\n",
    "An example of a regression problem could be: Predicting Google's share price.\n",
    "An example of a classification task could be: Predicting a person's favourite fruit.\n",
    "\n",
    "It's important to note that features in both classification and regression tasks can be a combination of continuous and categorical (we often need to transform categorical features into continuous ones or vice versa depending on the type of model we're using). \n",
    "\n",
    "## What do we mean by linear?\n",
    "\n",
    "An equation is **linear** if the highest degree of any of the the independent variables (i.e. $x$) is 1. If there's a term containing $x^2$ for example, the equation is no longer linear because the independent variable is being raised to a power higher than 1. \n",
    "\n",
    "\n",
    "## What does 'training' or 'fitting' a linear regression model mean?\n",
    "\n",
    "Linear regression is our first example of supervised learning. In supervised learning tasks, we:\n",
    "\n",
    "1. Obtain a dataset that consists of lots of data points, where each point consists of:\n",
    "\n",
    "    * A value for our label/response/target/dependent variable $y$\n",
    "    * Corresponding values for our features/predictors/independent variables $x$\n",
    "    \n",
    "    You can think of a single 'data point' or 'observation' as corresponding to a single row in a Pandas dataframe\n",
    "    \n",
    "2. Split the dataset into a training set that we'll use to fit or train our model, and a testing set that we'll use to evaluate our model's accuracy. A typical split is 80% of our data will be used for training, and 20% for testing. \n",
    "\n",
    "3. Train or fit our model. This will be different for different models. \n",
    "\n",
    "In linear regression, training is the process of finding the linear equation that best fits our data.\n",
    "\n",
    "In other words, we're finding the $\\beta$ values or **model coefficients** that give us the line of best fit:\n",
    "\n",
    "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
    "- Specifically, we are trying to find the line (mathematically) that minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "- Once we've learned these coefficients, we can use the model to predict the values for $y$, the dependent variable (or 'response') for new data points where we only have access to $x$, the features.\n",
    "\n",
    "\n",
    "Evaluation metrics for classification problems, such as accuracy, are not useful for regression problems. We need evaluation metrics designed for comparing continuous values.\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "**Mean absolute error (MAE)** is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean squared error (MSE)** is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root mean squared error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "Let's compare these metrics:\n",
    "\n",
    "- MAE is the easiest to understand, because it's the average error.\n",
    "- MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world. Also, MSE is continuous and differentiable, making it easier to use than MAE for optimization.\n",
    "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are **loss functions**, because we want to minimize them.\n",
    "\n",
    "## Why use linear regression?\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain.\n",
    "- Highly interpretable.\n",
    "- Model training and prediction are fast.\n",
    "- No tuning is required (excluding regularization).\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "- Well understood.\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias.\n",
    "- Can't automatically learn feature interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleaning\"></a>\n",
    "\n",
    "# <font color='blue'> Simple linear regression\n",
    "\n",
    "Let's work through a simple example with dummy data to understand how linear regression works. \n",
    "\n",
    "Imagine we have a data frame that describes house prices together with each house's internal area and number of bedrooms. (Note: this is dummy data!)\n",
    "\n",
    "Let's start by trying to model house price using a ***single variable only***: internal area.\n",
    "\n",
    "The general form of the equation we're trying to fit to our data is:\n",
    "\n",
    "`house price = a0 + a1*internal area`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression # import\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = pd.DataFrame({'house_price':[440000, 200000, 670000, 120000, 800000, 200000, 800000, 760000, 340000, 110000],\n",
    "                         'internal_area_sq_m':[100, 24, 120, 28, 150, 52, 160, 156, 117, 32],\n",
    "                        'bedrooms':[2, 1, 3, 1, 4, 2, 5, 4, 2, 1]})\n",
    "house_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data 80/20 into a training and a testing set.\n",
    "\n",
    "We'll train the model on the training set, and test how well it generalises on the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_df[['internal_area_sq_m']] # features\n",
    "y = house_df['house_price'] # labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use scikit-learn to fit our model and make predictions\n",
    "\n",
    "This bit is super simple with scikit-learn! We import scikit-learn, initialise the linear regression model, and then fit it to our data:\n",
    "\n",
    "**Step 1:** Import the class you plan to use from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Initialise the model\n",
    "\n",
    "* We've created an object that \"knows\" how to do linear regression, and is just waiting for data.\n",
    "* The ame of the object does not matter.\n",
    "* All parameters not specified are set to their defaults.\n",
    "* We can specify tuning parameters (aka \"hyperparameters\") during this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression() # initialise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\").\n",
    "\n",
    "- Model is \"learning\" the relationship between X and y in our \"training data.\"\n",
    "- Process through which learning occurs varies by model.\n",
    "- Occurs in-place.\n",
    "\n",
    "Note that 'X' and 'y' correspond to the correct columns in our 'votes' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train) # fit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! `linreg` is now a trained model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Inspect our trained model.\n",
    "\n",
    "Now we've fitted our linear regression model, we can look at the coefficients it's learned and evaluate how well the model fits our data using the **sum of squared errors** metric we defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = linreg.coef_\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = linreg.intercept_\n",
    "print(intercept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what the learned coefficient and intercept of our model is, we can write down a formula describing the learned relationship between internal area and sale price.\n",
    "\n",
    "`house price = -59308 + 5481*area_sq_m`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the intercept:\n",
    "\n",
    "- It is the value of $y$ when all independent variables are 0.\n",
    "- Here, it is the estimated vote share when a house has 0 internal area.\n",
    "- **Note:** It does not always make sense to interpret the intercept; why? \n",
    "\n",
    "Interpreting the \"area\" coefficient:\n",
    "\n",
    "- **Interpretation:** An increase of 1m2 in internal area is _associated with_ increasing the house price $a_1$\n",
    "- In this case, an increase of 1m2 in internal area is _associated with_ increasing the house price by £5481\n",
    "- This is not a statement of causation.\n",
    "- $a_1$ would be **negative** if an increase in internal area was associated with a **decrease** in house price.\n",
    "- $a_1$ would be **zero** if internal area is not at all associated with house price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Evaluate our model\n",
    "\n",
    "Exactly how well does our formula, or our 'line of best fit' fit our data?\n",
    "\n",
    "We can calculate the **mean squared error** and **root mean squared error** using scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_train, linreg.predict(X_train))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared TRAINING error: %f'% mse)\n",
    "print('Root mean squared TRAINING error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's not enough to know how well our model fits our training data; this is useless information if the model doesn't perform well on 'unseen', out of sample data from our testing set!\n",
    "\n",
    "Now we find our testing accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, linreg.predict(X_test))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared TESTING error: %f'% mse)\n",
    "print('Root mean squared TESTING error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret the RMSE as meaning that **on average, the model will get the sale price wrong by around £193,000!**\n",
    "\n",
    "Is this good? \n",
    "\n",
    "We can compare our model to a null model, or a baseline. \n",
    "\n",
    "In regression tasks, it's common for the baseline model to be **a model that always predicts the mean value of the dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_train)*np.ones(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_model = np.mean(y_train)*np.ones(len(y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, null_model)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Baseline model mean squared error: %f'% mse)\n",
    "print('Baseline model root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the **residuals** of our model; that is, the actual values of our target vs the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(linreg.predict(X_train),y_train)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Predict the response for a new data point\n",
    "\n",
    "This is the exciting bit! New observations are called \"out-of-sample\" data. Our model uses the information it learned during the model training process.\n",
    "\n",
    "Let's ask the model to make two predictions:\n",
    "\n",
    "* One in a house where the internal area is 150m2\n",
    "* One in a house where the internal area is 50m2\n",
    "\n",
    "To do this, our feature matrix is always a 2-D array where each row is a list of features. Since we only have a single feature, the internal area, each row will contain only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[150], [50]]\n",
    "linreg.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise: Linear regression with multiple features\n",
    "    \n",
    "Now let's use both features in our dataset to run our linear regression model. Now, the equation we're trying to fit looks like:\n",
    "\n",
    "`house price = a0 + a1*internal area + a2*bedrooms`\n",
    "\n",
    "Fill in the gaps in the code below to fit and evaluate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourselves of what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split out our features and dependent variable, and our training and testing sets. **Keep random state as 42**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_df[[ # fill this in ]] # features: instead of having a single feature here, we want to use TWO columns from our dataset\n",
    "y = house_df[# fill this in ] # labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(# fill this in  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now initialise our linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_2 =  # fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's fit it to our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_2.fit(# fill this in )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the intercepts and coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_2.# fill this in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_2.# fill this in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret this to mean that if we hold internal area constant, every extra bedroom will add around £600 to the house price.\n",
    "\n",
    "And if we hold bedroom numbers constant, every extra square metre will add around £5500 to the house price.\n",
    "\n",
    "Now, get the training error of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(# fill this in )\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared TRAINING error: %f'% mse)\n",
    "print('Root mean squared TRAINING error: %f'% rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the testing error..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(# fill this in )\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared TESTING error: %f'% mse)\n",
    "print('Root mean squared TESTING error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare to the baseline model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_model = np.mean(y_train)*np.ones(len(y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, null_model)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Baseline model mean squared error: %f'% mse)\n",
    "print('Baseline model root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Exercise 2: Linear regression to predict house sale price\n",
    "\n",
    "Now let's try this method out with a much bigger, real life dataset! \n",
    "\n",
    "Read in the dataset, which describes house prices and other features collected from Boston and downloaded from Kaggle: https://www.kaggle.com/prasadperera/the-boston-housing-dataset\n",
    "\n",
    "Read the dictionary, which you can find here. Familiarise yourself with the features in the dataset.\n",
    "\n",
    "What does each row represent? What does each column represent?\n",
    "\n",
    "* CRIM - per capita crime rate by town\n",
    "* ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS - proportion of non-retail business acres per town.\n",
    "* CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "* NOX - nitric oxides concentration (parts per 10 million)\n",
    "* RM - average number of rooms per dwelling\n",
    "* AGE - proportion of owner-occupied units built prior to 1940\n",
    "* DIS - weighted distances to five Boston employment centres\n",
    "* RAD - index of accessibility to radial highways\n",
    "* TAX - full-value property-tax rate per 10,000USD\n",
    "* PTRATIO - pupil-teacher ratio by town\n",
    "* LSTAT - \\% lower status of the population\n",
    "* MEDV - Median value of owner-occupied homes in 1000USDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('boston_housing.csv')\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect missing values, and remove rows with `NaN` values using the ``dropna()`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 70% training, 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = \n",
    "y = \n",
    "X_train, X_test, y_train, y_test = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n",
    "\n",
    "Use `sns.pairplot`, `sns.heatmap`, `describe` and `corr` to:\n",
    "\n",
    "(a) Create a pairplot of some of the different pairings of variables in our dataset (this might take a while depending on how fast your laptop is!)\n",
    "\n",
    "(b) Generate a correlation matrix\n",
    "\n",
    "(c) Visualise the correlation matrix with a heatmap\n",
    "\n",
    "Then, by visual inspection, discuss the following questions in your groups:\n",
    "\n",
    "(a) Which column is the target, or independent variable?\n",
    "\n",
    "(b) Which variables look like they're most strongly associated or correlated with house price?\n",
    "\n",
    "(c) Do the associations make intuitive sense? If not, why not? \n",
    "\n",
    "(d) Do some of the associations look like they describe causal relationships? Which ones? \n",
    "\n",
    "(e) Which of your variables are normally distributed with no significant outliers?\n",
    "\n",
    "**Decide which features to include in your model, using your knowledge of which features are normally distributed, and have significant outliers***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise and fit a linear regression model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_regression = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the mean squared error of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = \n",
    "rmse = \n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a residual plot to assess the goodness of fit of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your linear model on out of sample data\n",
    "\n",
    "Now we've trained our simple linear model, we can read in our testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the accuracy of our model on unseen data, using root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = \n",
    "rmse = \n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the performance of the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_null = \n",
    "\n",
    "mse =\n",
    "rmse = \n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the following questions:\n",
    "\n",
    "* Why is the testing accuracy of the model worse than the training accuracy?\n",
    "\n",
    "* Does our linear regression model perform better than the null model?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_to_python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
